newdata3 <- within(newdata3, {
PredictedProb <- plogis(fit)
LL <- plogis(fit - (1.96 * se.fit))
UL <- plogis(fit + (1.96 * se.fit))
})
newdata3 <- within(newdata3, {
PredictedProb <- plogis(fit)
LL <- plogis(fit - (1.96 * se.fit))
UL <- plogis(fit + (1.96 * se.fit))
})
head(newdata3)
ggplot(newdata3)
library(ggplot2)
install.packages("ggplot2")
install.packages("ggplot2")
ggplot
ggplot(newdata3)
library(ggplot2)
ggplot
ggplot(newdata3, aes(x = gre, y = PredictedProb)) + geom_ribbon(aes(ymin = LL, ymax = UL, fill = rank), alpha = 0.2) + geom_line(aes(colour = rank), size=1)
with(mylogit, null.deviance - deviance)
with(mylogit, df.null - df.residual)
with(mylogit, pchisq(null.deviance - deviance, df.null-df.residual))
with(mylogit, pchisq(null.deviance - deviance, df.null-df.residual, lower.tail=FALSE))
logLik(mylogit)
am.glm = glm(formula=am ~ hp + wt, data=mtcars, family=binomial)
newdata = data.frame(hp=120, wt=2.8)
predict(am.glm, newdata, type="response")
summary(am.glm)
library(MASS)
painters
painters$School
school = painters$School
school.freq = table(school)
school.freq
cbind(school.freq)
composition = painters$Composition
composition.freq = table(composition)
composition.freq
cbind(composition.freq)
school.relfreq = school.freq/nrow(painters)
school.relfreq
old = option(digits=1)
old = options(digits=1)
school.relfreq
school
options(old)
old = options(digits=1)
cbind(school.relfreq)
options(old)
barplot(school.freq)
colors = c("red", "yellow", "green", "violet", "orange", "blue", "pink", "cyan")
barplot(school.freq, col=colors)
install.packages("swirl")
library("swirl")
ls()
rm(list=ls))
rm(list=ls())
swirl()
5+7
info()
main()
swirl()
library(swirl)
install_from_swirl("Regression Models")
swirl()
0
main()
bye()
library(swirl)
install_from_swirl("Regression Models")
swirl()
plot(child ~ parent, galton)
plot(jitter(child,4)~ parent,galton)
regrline <- lm(child~parent, galton)
abline(regrline, lwd=3, col='red')
summary(regrline)
install.packages("UsingR")
library(UsingR);data(galton)
data(galton)
par(mfrow=c(1,2))
hist(galton$child,col="blue",breaks=1000)
library(UsingR)
install.packages(c("class", "ggplot2", "lme4", "Matrix", "mgcv", "mvtnorm", "party", "randomForest", "rattle", "Rcpp", "RCurl", "sandwich", "swirl"))
install.packages("UsingR")
library(UsingR); data(galton)
View(galton)
install.packages("swirl")
library(swirl)
swirl()
plot(child ~ parent, galton)
plot(jitter(child,4)~parent,galton)
regrline <- lm(child ~ parent,galton)
abline(regrline, lwd=3, col='red')
summary(regrline)
bye()
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
fit <- lm x~w)
fit <- lm(x~w)
fit <- lm(x~w)
summary(fit)
fit <- lm(w~x)
summary(fit)
swirl()
library(swirl)
install_from_swirl("R Programming")
swirl()
install_from_swirl("R Programming")
library(swirl)
swirl()
5+7
x <- 5+7
x
y <- x-3
y
z <- c(1.1, 9, 3.14)
c()
?c
z
c(z, 555, z)
z*2+100
my_sqrt <- sqrt(z)
my_sqrt <- sqrt(z-1)
my_sqrt
my_div <- z/my_sqrt
my_div
c(1,2,3,4) + c(1,10)
c(1,2,3,4) + c(0,10)
c(1,2,3,4) + c(0,10,100)
c(1,2,3,4) + c(0,10,1000)
z*2+1000
my
my_div
x <- 4
x
y <- 3
y + x
v <- c(1,2,5,8,9)
v
a <= apple
demo()
install.packages(c("aplpack", "bdsmatrix", "boot", "car", "class", "cluster", "codetools", "coin", "digest", "foreign", "Formula", "Hmisc", "httr", "KernSmooth", "labeling", "lattice", "manipulate", "MASS", "Matrix", "mgcv", "minqa", "mvtnorm", "nlme", "nnet", "party", "quantreg", "rattle", "RColorBrewer", "Rcpp", "RcppEigen", "RCurl", "reshape2", "rpart", "rpart.plot", "sandwich", "SparseM", "spatial", "survival", "swirl", "testthat", "UsingR"))
install.packages("aplpack")
install.packages("bdsmatrix")
install.packages("boot")
install.packages("car")
install.packages("class")
install.packages(c("cluster", "codetools", "coin", "digest", "foreign", "Formula", "Hmisc", "httr", "KernSmooth", "labeling", "lattice", "manipulate", "MASS", "Matrix", "mgcv", "minqa", "mvtnorm", "nlme", "nnet", "party", "quantreg", "rattle", "RColorBrewer", "Rcpp", "RcppEigen", "RCurl", "reshape2", "rpart", "rpart.plot", "sandwich", "SparseM", "spatial", "survival", "swirl", "testthat", "UsingR"))
install.packages("caret")
data(iris); library(ggplot2)
names(iris)
table(iris$Species)
inTrain <- createDataPartition(y=iris$Species,)
inTrain <- createDataPartition(y=iris$Species, p=.7, list=FALSE)
library(caret)
set.seed(3456)
inTrain <- createDataPartition(y=iris$Species, p=.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training); dim(testing)
qplot(Petal.Width,Sepal.Width,colour=Species,data=training)
modFit <- train(Species~.,method="rpart",data=training)
library(e1071)
install.packages("rpart")
modFit <- train(Species~.,method="rpart",data=training)
library(rpart)
modFit <- train(Species~.,method="rpart",data=training)
mean(abs(rnorm(100)))
rnorm(10)
pdf("xh.pdf") # set graphical output file
hist(rnorm(100) # generate 100 N(0,1) variates and plot their histogram
dev.off() # close the graphical output file
R CMD BATCH z.R
pdf ("xh.pdf")
hist(rnorm(100))
dev.off()
exit
exit()
close()
quit
quit()
pdf "xh.pdf")
pdf("xh.pdf")
hist(rnorm(100))
dev.off()
hist(rnorm(1000))
hist(rnorm(10000))
hist(rnorm(100000))
hist(rnorm(1000000))
hist(rnorm(10000000))
hist(rnorm(100000000))
quit()
quit()
x <- c(1,2,4)
q <- c(x,x,8)
x
q
x[3]
x <- c(1,2,4)
x[2:3]
mean(x)
sd(x)
y <- mean(x)
y
y # print out y
data()
mean(Nile)
sd(Nile)
hist(Nile)
hist(z,breaks=12)
getwd()
exit
quit()
library(shiny)
runExample("01_hello")
runExample()
runExample("02_text")
runExample("03_reactivity")
runExample("04_mpg")
runExample()
runExample("05_sliders")
runExample("06_tabsets")
runExample("07_widgets")
mkdir(App-1)
run(App-1)
runApp(App-1)
runApp("App-1")
getwd()
getwd()
library(Hmisc)
library(xlsx)
library(dplyr)
library(rattle)
data(tli)
library(xtable)
data(tli)
tli.table <- xtable(tli[1:20, ])
digits(tli.table)[c(2, 6)] <- 0
print(tli.table)
print(tli.table, type = "html")
source('~/.active-rstudio-document', echo=TRUE)
tli.table <- xtable(tli[1:20, ])
digits(tli.table) <- matrix( 0:4, nrow = 20, ncol = ncol(tli)+1 )
print(tli.table)
print(tli.table, type = "html")
rattle()
library(rattle)
rattle()
rattle()
setwd("/Volumes/HD2/Users/pstessel/Documents/Git_Repos/Titanic")
require(caret)
require(useful)
require(glmnet)
require(parallel)
require(doParallel)
require(reshape2)
require(stringr)
require(ROCR)
acs <- read.table("data/titanic_train.csv", sep = ",", header = TRUE, stringsAsFactors = FALSE)
head(acs)
# build predictor matrix
names(acs)
summary(survived)
summary(acs$survived)
summary(acs$Survived)
plot(acs$Survived)
histogram(acs$Survived)
dsname <- "acs"
ds <- get(dsname)
dim(ds)
dspath <- "/Volumes/HD2/Users/pstessel/Documents/Git_Repos/Titanic/data/titanic_train.csv"
titanic <- read.csv(dspath)
dim(titanic)
names(titanic)
str(titanic)
dsname <- "titanic"
ds <- get(dsname)
dim(ds)
# Step 1: Convenience of Table Data Frame ---------------------------------
# Another tip in dealing with larger datasets is to make use of tbl df() to add
# a couple of extra classes to the data frame. The simple aim here is to avoid
# the often made "mistake" of printing the whole data frame accidentally.
class(ds)
ds <-tbl_df(ds)
# Step 2: Review—Observations ---------------------------------------------
# Once we have loaded the dataset, the next step is to understand the shape of
# the dataset. We review the data using head() and tail() to get our first feel
# for the observations contained in the dataset. We also have a look at some
# random observations from the dataset to provide further insight.
head(ds)
tail(ds)
ds[sample(nrow(ds),6),]
# Step 2: dReview—Structure --------------------------------------------------------
str(ds)
# Review—Summary ----------------------------------------------------------
# We use summary() to preview the distributions
summary(ds)
# Step 2: Review — Meta Data Cleansing --------------------------------------
# We demonstrate some meta-data changes here.
# Normalise Variable Names
# Sometimes it is convenient to map all variable names to low- ercase. R is case
# sensitive, so doing this does change the variable names. This can be useful
# when different upper/lower case conventions are intermixed in names like
# Incm_tax_PyBl and remembering how to capitalise when interactively exploring
# the data with 1,000 such variables is an annoyance. We often see such variable
# names arising when we import data from databases which are often case
# insensitive. Here we use normVarNames() from rattle, which attempts to do a
# reasonable job of converting variables from a dataset into a standard form.
names(ds)
names(ds) <- normVarNames(names(ds))
# Step 2: Review  — Data Formats ------------------------------------------
# We may want to correct the format of some of the variables in our dataset. We might first
# check the data type of each variable.
# We note that the date variable is a factor rather than a date. Thus we may like to convert
# it into a date using lubridate.
View(ds)
View(ds)
names(ds)
names(ds) <- normVarNames(names(ds))
View(ds)
View(ds)
hist(ds$fare)
hist(log(ds$fare))
summary(ds$fare)
boxplot(ds$fare)
require(rattle)
rattle()
rattle()
rattle()
require(rattle)
rattle()
install.packages("rggobi")
install.packages("rggobi")
names(ds)
names(ds) <- normVarNames(names(ds))
(vars <- names(ds))
id <- c("passenger_id", "x_name")
ignore <- union(id, if (exists("risk")) risk)
# We might also identify any variable that has a unique value for every
# observation. These are sometimes identifiers as well and if so are candidates
# for ignoring.
(ids <- which(sapply(ds, function(x) length(unique(x))) == nrow(ds)))
ignore <- union(ignore, names(ids))
# All Missing
# We then remove any variables where all of the values are missing. There are
# none like this in the weather dataset, but in general across 1,000 variables,
# there may be some. We first count the number of missing values for each
# variable, and then list the names of those variables with only missing values.
mvc <- sapply(ds[vars], function(x) sum(is.na(x)))
mvn <- names(which(mvc == nrow(ds)))
ignore <- union(ignore, mvn)
# Many Missing
# Perhaps we also want to ignore variables with more than 70% of the values missing.
mvn <- names(which(mvc >= 0.7*nrow(ds)))
ignore <- union(ignore, mvn)
factors <- which(sapply(ds[vars], is.factor))
lvls <- sapply(factors, function(x) length(levels(ds[[x]])))
(many <- names(which(lvls > 20)))
# Constants
# Ignore variables with constant values.
(constants <- names(which(sapply(ds[vars], function(x) all(x == x[1L])))))
ignore <- union(ignore, constants)
(constants <- names(which(sapply(ds[vars], function(x) all(x == x[1L])))))
ignore <- union(ignore, constants)
# Step 3: Clean — Identify Corelated Variables ----------------------------
mc <- cor(ds[which(sapply(ds, is.numeric))], use="complete.obs")
mc[upper.tri(mc, diag=TRUE)] <- NA
mc <-
mc %>%
abs() %>%
data.frame() %>%
mutate(var1=row.names(mc)) %>%
gather(var2, cor, -var1) %>%
na.omit()
mc <- mc[order(-abs(mc$cor)),]
mc
?gather
require(randomForest)
require(dplyr)
require(lubridate)
require(Fselector)
install.packages("fsel")
install.packages("lubridate")
mc <- cor(ds[which(sapply(ds, is.numeric))], use="complete.obs")
mc[upper.tri(mc, diag=TRUE)] <- NA
mc <-
mc %>%
abs() %>%
data.frame() %>%
mutate(var1=row.names(mc)) %>%
gather(var2, cor, -var1) %>%
na.omit()
mc <- mc[order(-abs(mc$cor)),]
mc
View(mc)
View(mc)
mc <- mc[order(-abs(mc$cor)),]
mc <- cor(ds[which(sapply(ds, is.numeric))], use="complete.obs")
mc[upper.tri(mc, diag=TRUE)] <- NA
mc <-
mc %>%
abs() %>%
data.frame() %>%
mutate(var1=row.names(mc)) %>%
gather(var2, cor, -var1) %>%
na.omit()
mc <- mc[order(-abs(mc$cor)),]
mc
require(randomForest)
require(dplyr)
require(lubridate)
require(Fselector)
mc <- cor(ds[which(sapply(ds, is.numeric))], use="complete.obs")
mc[upper.tri(mc, diag=TRUE)] <- NA
mc <-
mc %>%
abs() %>%
data.frame() %>%
mutate(var1=row.names(mc)) %>%
gather(var2, cor, -var1) %>%
na.omit()
require(tidyr)
mc <- cor(ds[which(sapply(ds, is.numeric))], use="complete.obs")
mc[upper.tri(mc, diag=TRUE)] <- NA
mc <-
mc %>%
abs() %>%
data.frame() %>%
mutate(var1=row.names(mc)) %>%
gather(var2, cor, -var1) %>%
na.omit()
mc <- mc[order(-abs(mc$cor)),]
mc
length(vars)
vars <- setdiff(vars, ignore)
length(vars)
names(vars)
ds <- ds[vars]
model_vars <- list(names(ds))
names(ds)
dsX <-
build.x(
survived ~ pclass + sex + age + sib_sp + parch + ticket + fare + cabin + embarked -
1, data = acs, contrasts = FALSE
)
View(ds)
View(ds)
dsX <-
build.x(
survived ~ pclass + sex + age + sib_sp + parch + ticket + fare + cabin + embarked -
1, data = ds, contrasts = FALSE
)
class(dsX)
str(ds)
dsX <-
build.x(
survived ~ pclass + sex + age + sib_sp + parch + fare + cabin + embarked -
1, data = ds, contrasts = FALSE
)
ds$survived <- with(ds, survived==1)
ds$survived
View(ds)
View(ds)
View(titanic)
View(titanic)
source('/Volumes/HD2/Users/pstessel/Documents/Git_Repos/Titanic/titanic_elastic_net.R', echo=TRUE)
str(ds)
dsX <-
build.x(
survived ~ pclass + sex + age + sib_sp + parch + fare + embarked -
1, data = ds, contrasts = FALSE
)
ds$survived <- with(ds, survived==1)
ds$survived
names(ds)
str(ds)
dsX <-
build.x(
survived ~ pclass + sex + age + sib_sp + parch + fare + embarked -
1, data = ds, contrasts = FALSE
)
ds$pclass <- as.factor(ds$pclass)
str(ds)
table(age)
table(ds$age)
?table
table(ds$age, useNA = "ifany")
hist(ds$age)
hist(log((ds$age))
hist(log((ds$age))
hist(log((ds$age)))
hist(ds$age)
quantile(ds$age)
quantile(ds$age, na.rm = TRUE)
boxplot(ds$age)
?quantile
quantile(ds$age, probs = seq(0, 1, 0.25), na.rm = TRUE)
quantile(ds$age, probs = seq(0, 1, 0.10), na.rm = TRUE)
quantile(ds$age, probs = seq(0, 1, 0.1), na.rm = TRUE)
mean(ds$age)
test <- mean(ds$age)
mode(ds$age)
summary(ds$age)
str(ds$age)
summary(ds$age)
dsX <-
build.x(
survived ~ pclass + sex + age + sib_sp + parch + fare + embarked -
1, data = ds, contrasts = FALSE
)
table(ds$age, useNA = "ifany")
